
# json-sum

Данная репа является решением к про параллельное вычисление суммы всех чисел среди большого количества обьектов


## Использование и метод запуска

Программа первым аргументов принимает количество горутин, вторым файл который он читает. Если ничего не дано, то он использует дефолтные значения. Запуск довольно прост, и типичен

```bash
go run . 20 "./test/test.json"
```

Также в папке `cmd` я написал генератор json исходят из условий, в константах которых можно указать название файла для теста, а также количеств обьектов внутри него. Запускается он следующей командой

```bash
go run ./cmd
```

В конце также он посчитает сумма чисел внутри сгенерированной json


## Детали реализаций

В качестве реализаций я написал несколько решений

* самым первым решением, было то что просто пришло мне в голову, разделить обьект на более мелкие чанки, отправить ее моим воркерам, отправить сумму в канал ответов,и позднее уже вычислить ее

* второе решение, такое же как и первое. Однако я не теряю времени на разделение обьектов, и отправку ее в воркеры. я сразу же суммирую, решая задачу "на месте"

* третье и четвертое решение уже являются реализациями через mutex и atomic. Мне достаточно просто суммировать все мой мини суммы

Мне показалось что 1 миллион обьектов слишком маловатом. Я решил тестировать скорость этих решений на 100 миллионах обьектов. Вот такие результаты я получил.

```bash
// using channels
kamal@kamal-Vivobook-ASUSLaptop-M6500IH-M6500IH:~/Desktop/work/mechta$ go run .
48.013881ms
89054

// using mutex
kamal@kamal-Vivobook-ASUSLaptop-M6500IH-M6500IH:~/Desktop/work/mechta$ go run .
53.530197ms
89054

// using atomic
kamal@kamal-Vivobook-ASUSLaptop-M6500IH-M6500IH:~/Desktop/work/mechta$ go run .
50.127719ms
89054

// default (no goroutine)
kamal@kamal-Vivobook-ASUSLaptop-M6500IH-M6500IH:~/Desktop/work/mechta$ go run .
86.583407ms
89054
```

Исходя из результатов, самым быстрым решением оказалось `solution2` в котором я использовал канал, в качестве метода записи результата

